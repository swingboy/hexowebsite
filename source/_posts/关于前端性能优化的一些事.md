---
title: 关于前端性能优化的一些事
date: 2019-12-10 20:25:37
tags: 技术
---

前端性能优化零碎知识点的一些东西，可能相对比较不太成”体统“简单理下，零碎的但必要的知识点。从“输入 URL 到页面加载完成，发生了什么”的角度简单梳理一遍

- DNS 解析
- TCP 连接
- HTTP 请求发送
- 服务端处理请求，响应返回
- 浏览器拿到响应数据，解析响应内容，把解析的结果展示给用户

稍微详细点儿：

- 回车url到cpu中断，响应键盘操作
- 浏览器解析url到开启网络请求线程
- DNS解析域名映射对应的ip地址（及arp地址解析，实现IP地址到MAC地址的转换。）
- 开启网络线程到发出一个完整的http请求
- 从服务器接收到请求到对应后台接收到请求
- 后台和前台的http交互
- 浏览器接收到http数据包后的解析流程（解析html-词法分析然后解析成dom树、解析css生成css规则树、合并成render树，然后layout、painting渲染、复合图层的合成、GPU绘制、外链资源的处理、loaded和domcontentloaded等）
- JS引擎解析过程（JS的解释阶段，预处理阶段，执行阶段生成执行上下文，VO，作用域链、回收机制等等）

## DNS查询 
我们知道dns解析是耗时的。

对于页面请求域名，如果DNS Lookup 时间过长会引起白屏的时间过长
对于图片对应的域名，如果DNS Lookup 时间过长，白图的时间也会过长

如果解析域名过多，会让首屏加载变得过慢。

dns解析成IP，大致流程：

如果浏览器有缓存，直接使用浏览器缓存，否则使用本机缓存，再没有的话就是用host
如果本地没有，就向dns域名服务器查询（中间可能还会经过路由器、ISP 的缓存），查询到对应的IP

- 域名查询时有可能是经过了CDN调度器的（如果有cdn存储功能的话）

## DNS优化

DNS Prefetch，即DNS预解析就是根据浏览器定义的规则，提前解析之后可能会用到的域名，使解析结果缓存到系统缓存中，缩短DNS解析时间，来提高网站的访问速度。

* 当然还有设置合理的TTL时间、DNS多点就近部署架构升级、基于Anycast的DNS解析架构（未来DNS的优化方向）

*** 打开和关闭DNS预读取  *** 

可以通过在服务器端发送 X-DNS-Prefetch-Control 报头，或是在文档中使用值为 http-equiv 的标签：
&lt;meta http-equiv="x-dns-prefetch-control" content="off"&gt;

强制查询特定主机名 
你可以通过使用 rel 属性值为 link type 中的 dns-prefetch 的 标签来对特定域名进行预读取：
&lt;link rel="dns-prefetch" href="http://www.xxx.com/"&gt;


## HttpDNS

我们知道，DNS一定会存在的问题就是：域名更新问题、解析延迟。那HTTPDns就登场了

- 定义：不走传统的DNS解析，而是自己搭建基于HTTP协议的DNS服务器集群，分布在多个地点和多个运营商，当客户端需要DNS解析的时候，直接通过HTTP协议进行请求这个服务器集群，获得就近的地址。

HttpDNS是通过ip直接请求http获取服务器A记录地址，不存在向本地运营商询问domain解析过程，所以从根本避免了劫持问题。同时由于是ip直接访问省掉了一次domain解析过程，可以在一定程度上降低平均访问延迟。

## http

http耗时 = TCP握手 通过三次握手建立连接（四次挥手）
https耗时 = TCP握手 + SSL握手


http请求过程（请求应答模式）：
第一次: CLIENT----syn----->SERVER
第二次: SERVER----ack,syn---->CLIENT
第三次: CLIENT----ack----->SERVER
这样，从client---->server, server---->client各自通过一次syn,ack形成闭环，理论上形成了一个近似可靠的通信。

类似于TCP的三次握手，四次挥手的四步：
Client---fin,ack--->Server
Server---ack---->Clinet
Server---fin,ack--->Client
Client----ack----->Server

- SYN：同步序列编号（Synchronize Sequence Numbers）。是TCP/IP建立连接时使用的握手信号。在客户机和服务器之间建立正常的TCP网络连接时，客户机首先发出一个SYN消息，服务器使用SYN+ACK应答表示接收到了这个消息，最后客户机再以ACK消息响应。这样在客户机和服务器之间才能建立起可靠的TCP连接，数据才可以在客户机和服务器之间传递。
- ACK (Acknowledgement）即是确认字符，在数据通信中，接收站发给发送站的一种传输类控制字符。表示发来的数据已确认接收无误。
在TCP/IP协议中，如果接收方成功的接收到数据，那么会回复一个ACK数据。通常ACK信号有自己固定的格式,长度大小,由接收方回复给发送方。

## http1.0、1.1、2.0区别与联系

http1.1与http1.0 的最大区别就是：长链接、节约带宽、HOST域
与性能相关的是：长链接。HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。
节约带宽：HTTP 1.1支持只发送header信息(不带任何body信息)，如果服务器认为客户端有权限请求服务器，则返回100，否则返回401。客户端如果接受到100，才开始把请求body发送到服务器。这样当服务器返回401的时候，客户端就可以不用发送请求body了，节约了带宽。另外HTTP还支持传送内容的一部分。这样当客户端已经有一部分的资源后，只需要跟服务器请求另外的部分资源即可。这是支持文件断点续传的基础。

哪怕如此，HTTP1.1还是存在效率问题。单个 TCP 连接在同一时刻只能处理一个请求，是说：两个请求的生命周期不能重叠，任意两个 HTTP 请求从开始到结束的时间在同一个 TCP 连接里不能重叠。（虽然有了管道机制pipelining，在同一个TCP链接里，客户端可以发送多个请求，但是服务器还是按照顺序，先回应前面的，完成后，在回应后面的）

问题一：串行的文件传输。当请求a文件时，b文件只能等待，等待a连接到服务器、服务器处理文件、服务器返回文件，这三个步骤。我们假设这三步用时都是1秒，那么a文件用时为3秒，b文件传输完成用时为6秒，依此类推。（注：此项计算有一个前提条件，就是浏览器和服务器是单通道传输）
问题二：连接数过多。我们假设Apache设置了最大并发数为300，因为浏览器限制，浏览器发起的最大请求数为6，也就是服务器能承载的最高并发为50，当第51个人访问时，就需要等待前面某个请求处理完成。

然后http2.0 来了 解决这些问题

解决第一个：在HTTP1.1的协议中，我们传输的request和response都是基本于文本的，这样就会引发一个问题：所有的数据必须按顺序传输，比如需要传输：hello world，只能从h到d一个一个的传输，不能并行传输，因为接收端并不知道这些字符的顺序，所以并行传输在HTTP1.1是不能实现的。

- HTTP/2引入二进制数据帧和流的概念，其中帧对数据进行顺序标识，这样浏览器收到数据之后，就可以按照序列对数据进行合并，而不会出现合并后数据错乱的情况。同样是因为有了序列，服务器就可以并行的传输数据，这就是流所做的事情。

解决第二个问题：HTTP/2对同一域名下所有请求都是基于流，也就是说同一域名不管访问多少文件，也只建立一路连接。同样Apache的最大连接数为300，因为有了这个新特性，最大的并发就可以提升到300，比原来提升了6倍！

综上HTTP1.1与HTTP 2.0的主要区别
- 多路复用
- 二进制分帧
- 首部压缩
- 服务器推送

HTTP 2.0 采用 HTTPS ，HTTPS 基于 SSL/TLS。现在绝大部分的站点都会采用https，也就会引入hsts。

HSTS的作用是强制客户端（如浏览器）使用HTTPS与服务器创建连接。HSTS 的作用是为了在用户通过 HTTP 访问网站时不需要服务器做 301/302 跳转，直接一个 307 本地强制使用 HTTPS 访问网站，这可以防止用户在第一次发出请求时被劫持，也减少了一次请求。

## https过程
如何如何加密、解密。对称与非对称加密，证书如何生成

## 负载均衡

nginx实现负载均衡的几种方式

## 响应

### http 缓存

缓存可以简单的划分成两种类型：强缓存（200 from cache）与协商缓存（304）
优先级较高的是强缓存，在命中强缓存失败的情况下，才会走协商缓存。

强缓存是利用 http 头中的 Expires 和 Cache-Control 两个字段来控制的。强缓存中，当请求再次发出时，浏览器会根据其中的 expires 和 cache-control 判断目标资源是否“命中”强缓存，若命中则直接从缓存中获取资源，不会再与服务端发生通信。

协商缓存依赖于服务端与浏览器之间的通信。协商缓存机制下，浏览器需要向服务器去询问缓存的相关信息，进而判断是重新发起请求、下载完整的响应，还是从本地获取缓存的资源。如果服务端提示缓存资源未改动（Not Modified），资源会被重定向到浏览器缓存，这种情况下网络请求对应的状态码是 304

罗列下一些header 头


#### http1.0中：  
Pragma：严格来说，它不属于专门的缓存控制头部，但是它设置no-cache时可以让本地强缓存失效（属于编译控制，来实现特定的指令）
Expires：（expires: Wed, 11 Sep 2017 13:20:20 GMT）expires 是一个时间戳，接下来如果我们试图再次向服务器请求资源，浏览器就会先对比本地时间和 expires 的时间戳，如果本地时间小于 expires 设定的过期时间，那么就直接去缓存中取这个资源。 （expires对应服务器端时间）
If-Modified-Since/Last-Modified：
属于协商缓存的内容，其中浏览器的头部是If-Modified-Since，而服务端的是Last-Modified，它的作用是，在发起请求时，如果If-Modified-Since和Last-Modified匹配，那么代表服务器资源并未改变，因此服务端不会返回资源实体，而是只返回头部，通知浏览器可以使用本地缓存。（精确到1s以内）

#### http1.1中
Cache-Control：缓存控制头部，有no-cache、max-age、no-store、public、private、s-maxage等多种取值
* Max-Age：服务端配置的，用来控制强缓存，在规定的时间之内，浏览器无需发出请求，直接使用本地缓存，（max-age=3600，而且它值得是绝对时间，由浏览器自己计算）
* no-cache绕开了浏览器：我们为资源设置了no-cache 后，每一次发起请求都不会再去询问浏览器的缓存情况，而是直接向服务端去确认该资源是否过期（即走我们下文即将讲解的协商缓存的路线）
* no-store比较绝情，顾名思义就是不使用任何缓存策略。在no-cache的基础上，它连服务端的缓存确认也绕开了，只允许你直接向服务端发送请求、并下载完整的响应。
* public 可向任意方提供相应的缓存。如果我们为资源设置了 public，那么它既可以被浏览器缓存，也可以被代理服务器缓存
* private 仅向特点用户返回相应。如果我们设置了 private，则该资源只能被浏览器缓存。
* s-maxage 公共缓存服务器相应的最大age值。s-maxage 就是用于表示 cache 服务器上（比如 cache CDN）的缓存的有效时间的（s-maxage仅在代理服务器中生效，客户端中我们只考虑max-age。）
当然还有其他的类似must-revalidata、proxy-revalidate

If-None-Match/E-tag: 这两个是成对出现的，属于协商缓存的内容，其中浏览器的头部是If-None-Match，而服务端的是E-tag.发出请求后，如果If-None-Match和E-tag匹配，则代表内容未变，通知浏览器使用本地缓存，和Last-Modified不同，E-tag更精确，它是类似于指纹一样的东西，基于FileEtag INode Mtime Size生成，也就是说，只要文件变，指纹就会变，而且没有1s精确度的限制。

*** Max-Age相比Expires***
Expires使用的是服务器端的时间.但是有时候会有这样一种情况-客户端时间和服务端不同步.那这样，可能就会出问题了，造成了浏览器本地的缓存无用或者一直无法过期
所以一般http1.1后不推荐使用Expires.而Max-Age使用的是客户端本地时间的计算，因此不会有这个问题,因此推荐使用Max-Age。(如果同时启用了Cache-Control与Expires，Cache-Control优先级高。)

*** E-tag相比Last-Modified ***

Last-Modified：表明服务端的文件最后何时改变的,它有一个缺陷就是只能精确到1s，然后还有一个问题就是有的服务端的文件会周期性的改变，导致缓存失效
E-tag：是一种指纹机制，代表文件相关指纹,只有文件变才会变，也只要文件变就会变，也没有精确时间的限制，只要文件一遍，立马E-tag就不一样了(如果同时带有E-tag和Last-Modified，服务端会优先检查E-tag)



![](/imgs/关于前端性能优化的一些事/huancun.jpeg)


如何选择：
![](/imgs/关于前端性能优化的一些事/image.png)

### 页面解析

浏览器内核拿到内容后，渲染步骤大致可以分为以下几步：
1. 解析HTML，构建DOM树
2. 解析CSS，生成CSS规则树
3. 合并DOM树和CSS规则，生成render树
4. 布局render树（Layout/reflow），负责各元素尺寸、位置的计算（从根节点递归调用，计算每一个元素的大小、位置等）
5. 绘制render树（paint），绘制页面像素信息。（在这一步中浏览器会根据我们的 DOM 代码结果，把每一个页面图层转换为像素，并对所有的媒体文件进行解码。）
6. 浏览器会将各层的信息发送给GPU，GPU会将各层合成（composite），显示在屏幕上

### HTML解析，构建DOM

渲染树（Render-Tree）的关键渲染路径中，要求同时具有 DOM 和 CSSOM，之后才会构建渲染树。即，HTML 和 CSS 都是阻塞渲染的资源。  
减少DOM元素的数量、而且尽量少用iframe更要杜绝404


### 解析CSS
CSS下载时异步，不会阻塞浏览器构建DOM树.但是会阻塞渲染，也就是在构建render时，会等到css下载解析完毕后才进行（这点与浏览器优化有关，防止css规则不断改变，避免了重复的构建）
CSS 是阻塞渲染的资源。需要将它尽早、尽快地下载到客户端，以便缩短首次渲染的时间。

- media query声明的CSS是不会阻塞渲染的

精简 CSS 并尽快提供它.除此之外，还可以用媒体类型（media type）和媒体查询（media query）来解除对渲染的阻塞。
```
&lt;link href="index.css" rel="stylesheet"&gt;
&lt;link href="print.css" rel="stylesheet" media="print"&gt;
&lt;link href="other.css" rel="stylesheet" media="(min-width: 30em) and (orientation: landscape)"&gt;
```

保持简单，不要使用嵌套过多过于复杂的选择器。
通配符和属性选择器效率最低，需要匹配的元素最多，尽量避免使用。
不要使用类选择器和ID选择器修饰元素标签，如h3#markdown-content，这样多此一举，还会降低效率。
不要为了追求速度而放弃可读性与可维护性。
不要使用@import
尽量减少使用昂贵属性，如box-shadow/border-radius/filter/透明度/:nth-child等

CSS方法论BEM9，OOCSS10，SUIT11，SMACSS12，ITCSS13，Enduring CSS14等

***选择器优先级：***

选择器类型
下面列表中，选择器类型的优先级是递增的：
* 1.类型选择器（例如，h1）和伪元素（例如，::before）
* 2.类选择器 (例如，.example)，属性选择器（例如，[type="radio"]）和伪类（例如，:hover）
* 3.ID 选择器（例如，#example）。

通配选择符（universal selector）（*）关系选择符（combinators）（+, >, ~, ' ', ||）和 否定伪类（negation pseudo-class）（:not()）对优先级没有影响。（但是，在 :not() 内部声明的选择器会影响优先级）。
给元素添加的内联样式 (例如，style="font-weight:bold") 总会覆盖外部样式表的任何样式 ，因此可看作是具有最高的优先级。

总结：
important 》内联-》id 》class = 属性 = 伪类 》标签 = 伪元素 》 通配符（*）
important声明 1,0,0,0
ID选择器 0,1,0,0
类选择器 0,0,1,0
伪类选择器 0,0,1,0
属性选择器 0,0,1,0
标签选择器 0,0,0,1
伪元素选择器 0,0,0,1
通配符选择器 0,0,0,0


1、为什么一再强调css放在头部 ？
其实现代浏览器为了更好的用户体验,渲染引擎将尝试尽快在屏幕上显示的内容。它不会等到所有HTML解析之前开始构建和布局渲染树。部分的内容将被解析并显示。也就是说浏览器能够渲染不完整的dom树和cssom，尽快的减少白屏的时间。假如我们将js放在header，js将阻塞解析dom，dom的内容会影响到First Paint，导致First Paint延后。所以说我们会将js放在后面，以减少First Paint的时间，但是不会减少DOMContentLoaded被触发的时间。

2、css 逆向匹配为什么会提高匹配效率？
HTML 结构变复杂，CSS 规则表变庞大，那么，逆向匹配的优势就远大于正向匹配了，因为匹配的情况远远低于不匹配的情况。另外，如果在选择器结尾加上通配符「*」，那么「逆向匹配」的优势就大打折扣了，这也就是很多优化原则提到的「尽量避免在选择器末尾添加通配符」的原因。


### js 引擎的解析流程
JS脚本资源的处理有几个特点：
- 阻塞浏览器的解析，也就是说发现一个外链脚本时，需等待脚本下载完成并执行后才会继续解析HTML
- 浏览器的优化，一般现代浏览器有优化，在脚本阻塞时，也会继续下载其它资源（当然有并发上限），但是虽然脚本可以并行下载，解析过程仍然是阻塞的，也就是说必须这个脚本执行完毕后才会接下来的解析，并行下载只是一种优化而已

所以，不管外链还是内部脚本，都应当尽量放在页面底部。

前面有提到遇到JS脚本时，会等到它的执行，实际上是需要引擎解析的

但是可以加上defer或async属性，这样脚本就变成异步的了，可以等到解析完毕后再执行

- defer与async的区别是：defer要等到整个页面在内存中正常渲染结束（DOM 结构完全生成，以及其他脚本执行完成），才会执行；async一旦下载完，渲染引擎就会中断渲染，执行这个脚本以后，再继续渲染。
- 即：defer是“渲染完再执行”，async是“下载完就执行”。
- 另外，如果有多个defer脚本，会按照它们在页面出现的顺序加载，而多个async脚本是不能保证加载顺序的。
- 注意 async 与 defer 属性对于 inline-script 都是无效的。

js引擎对JS的处理过程：

* 1. 读取代码，进行词法分析（Lexical analysis），然后将代码分解成词元（token）
* 2. 对词元进行语法分析（parsing），然后将代码整理成语法树（syntax tree）
* 3. 使用翻译器（translator），将代码转为字节码（bytecode） 
* 4. 使用字节码解释器（bytecode interpreter），将字节码转为机器码

- 鉴于js引擎会在编译阶段进行数项的性能优化。其中有些优化依赖于能够根据代码的词法进行静态分析，并预先确定所有变量和函数的定义位置，才能在执行过程中快速找到标识符。但如果引擎在代码中发现了 eval(..) 或 with，最坏的情况下不会做出优化。代码执行会更慢。尽量避免使用。

#### JS的解释阶段

JS是解释型语言，所以它无需提前编译，而是由解释器实时运行  
为了提高运行速度，现代浏览器一般采用即时编译（JIT-Just In Time compiler）  

即字节码只在运行时编译，用到哪一行就编译哪一行，并且把编译结果缓存（inline cache）这样整个程序的运行速度能得到显著提升。

而且，不同浏览器策略可能还不同，有的浏览器就省略了字节码的翻译步骤，直接转为机器码（如chrome的v8）
总结起来可以认为是： 核心的JIT编译器将源码编译成机器码运行

#### 预处理阶段
1、分号补全
2、变量提升
3、...

### JS的执行阶段

整个执行流程中大致包含以下几个重要部分：

* 执行上下文，执行堆栈（如全局上下文，当前活动上下文）
* VO（变量对象）和AO（活动对象）
* 作用域链
* this机制

减少闭包释放内存资源

求值策略：
"传值调用"（call by value）
"传名调用"（call by name）



#### 垃圾回收
常用的两种垃圾回收规则
* 标记清除
* 引用计数

Javascript引擎基础GC方案是（simple GC）：mark and sweep（标记清除）
* 遍历所有可访问的对象，回收已不可访问的对象。

need to do 
降低内存泄露的风险
设置定时器的回收
dom元素的回收
事件的回收
卸载组件之后对应内存的释放
通过WeakMap(其中的键是弱引用的。其键必须是对象，而值可以是任意的)解决内存泄漏问题


## 闭包
闭包是指有权访问另外一个函数作用域中的变量的函数.可以理解为(能够读取其他函数内部变量的函数)

作用: 正常函数执行完毕后,里面声明的变量被垃圾回收处理掉,但是闭包可以让作用域里的变量,在函数执行完之后依旧保持没有被垃圾回收处理掉。

* 应用闭包的主要场合是：设计私有的方法和变量。

缺陷：闭包的缺点就是常驻内存会增大内存使用量，并且使用不当很容易造成内存泄露。如果不是因为某些特殊任务而需要闭包，在没有必要的情况下，在其它函数中创建函数是不明智的，因为闭包对脚本性能具有负面影响，包括处理速度和内存消耗。

适当减少闭包的使用。

## event loop

微任务，宏任务。理解事件循环机制，巧用宏任务与微任务。

Event Loop 过程浅析
- Javascript 有一个 main thread 主线程和 call-stack 调用栈(执行栈)，所有的任务都会被放到调用栈等待主线程执行。

JS 调用栈
* JS 调用栈是一种后进先出的数据结构。当函数被调用时，会被添加到栈中的顶部，执行完成之后就从栈顶部移出该函数，直到栈内被清空。

同步任务、异步任务
* js 单线程中的任务分为同步任务和异步任务。同步任务会在调用栈中按照顺序排队等待主线程执行，异步任务则会在异步有了结果后将注册的回调函数添加到任务队列(消息队列)中等待主线程空闲的时候，也就是栈内被清空的时候，被读取到栈中等待主线程执行。任务队列是先进先出的数据结构。  
Event Loop
* 调用栈中的同步任务都执行完毕，栈内被清空了，就代表主线程空闲了，这个时候就会去任务队列中按照顺序读取一个任务放入到栈中执行。每次栈内被清空，都会去读取任务队列有没有任务，有就读取执行，一直循环读取-执行的操作，就形成了事件循环。


## Flush 队列

现在浏览器，不会在每次 DOM 操作都即时地反馈一次回流或重绘。它自己缓存了一个 flush 队列，把我们触发的回流与重绘任务都塞进去，待到队列里的任务多起来、或者达到了一定的时间间隔，再将这些任务进行出队。

回流（Reflow）与重绘（Repaint）

documentFragment（DocumentFragment 接口表示一个没有父级文件的最小文档对象。它被当做一个轻量版的 Document 使用，用于存储已排好版的或尚未打理好格式的XML片段。因为，DocumentFragment 不是真实 DOM 树的一部分，它的变化不会引起 DOM 树的重新渲染的操作（reflow），且不会导致性能等问题。）
document.createDocumentFragment（创建document fragment）

### 回流

页面初始化  
DOM结构改变  
窗口resize  
render树变化  
浏览器为了获得某些值会触发回流  
* offset(Top/Left/Width/Height)
* scroll(Top/Left/Width/Height)
* cilent(Top/Left/Width/Height)
* width,height
* 调用了getComputedStyle()或者IE的currentStyle（getComputedStyle，因为它需要获取祖先节点的一些信息进行计算（譬如宽高等））
* ...

## 简单层与复合层

简介：
可以认为默认只有一个复合图层，所有的DOM节点都是在这个复合图层下的
如果开启了硬件加速功能，可以将某个节点变成复合图层
复合图层之间的绘制互不干扰，由GPU直接控制
absolute布局（fixed也一样），虽然可以脱离普通文档流，但它仍然属于默认复合层。
而简单图层中，就算是absolute等布局，变化时不影响整体的回流，但是由于在同一个图层中，仍然是会影响绘制的，因此做动画时性能仍然很低。而复合层是独立的，所以一般做动画推荐使用硬件加速
尽量不要大量使用复合图层，否则由于资源消耗过度，页面反而会变的更卡


硬件加速时请使用index
使用硬件加速时，尽可能的使用index，防止浏览器默认给后续的元素创建复合层渲染

具体的原理：
* webkit CSS3中，如果这个元素添加了硬件加速，并且index层级比较低，
* 那么在这个元素的后面其它元素（层级比这个元素高的，或者相同的，并且releative或absolute属性相同的），
* 会默认变为复合层渲染，如果处理不当会极大的影响性能

*** 简单点理解，其实可以认为是一个隐式合成的概念：如果a是一个复合图层，而且b在a上面，那么b也会被隐式转为一个复合图层，这点需要特别注意 ***

如何变成复合图层（硬件加速）?
将该元素变成一个复合图层，就是传说中的硬件加速技术
最常用的方式：translate3d、translateZ

opacity属性/过渡动画（需要动画执行的过程中才会创建合成层，动画没有开始或结束后元素还会回到之前的状态）
will-chang属性,一般配合opacity与translate使用（而且经测试，除了上述可以引发硬件加速的属性外，其它属性并不会变成复合层），作用是提前告诉浏览器要变化，这样浏览器会开始做一些优化工作（这个最好用完后就释放）

video、iframe、canvas、webgl等元素、flash插件

* Chrome源码调试 -> More Tools -> Rendering -> Layer borders中看到，黄色的就是复合图层信息


## 图片

遇到图片等资源时，直接就是异步下载，不会阻塞解析，下载完毕后直接用图片替换原有src的地方

- 一般来说：图片提前指定宽高或者脱离文档流，能有效减少因图片加载导致的页面回流

JPEG
特点：有损压缩、体积小、加载快、不支持透明
适用场景：JPG 适用于呈现色彩丰富的图片，在我们日常开发中，JPG 图片经常作为大的背景图、轮播图或 Banner 图出现。
缺陷：处理矢量图形和 Logo 等线条感较强、颜色对比强烈的图像时，人为压缩导致的图片模糊会相当明显,而且不支持透明

PNG-8 与 PNG-24
特点：无损压缩、质量高、体积大、支持透明
适用场景：呈现小的 Logo、颜色简单且对比强烈的图片或背景等。
缺陷：大

SVG
特点：文本文件、体积小、不失真、兼容性好。
* SVG 与 PNG 和 JPG 相比，文件体积更小，可压缩性更强。
缺点：渲染成本比较高。SVG 是可编程的，学习成本。

Base64
特点：文本文件、依赖编码、小图标解决方案
* Base64 并非一种图片格式，而是一种编码方式
* Base64 是一种用于传输 8Bit 字节码的编码方式，通过对图片进行 Base64 编码，我们可以直接将编码结果写入 HTML 或者写入 CSS，从而减少 HTTP 请求的次数。
适用场景：小图
缺点：Base64 编码后，图片大小会膨胀为原文件的 4/3（这是由 Base64 的编码原理决定的。大的图片不建议使用


WebP
特点：WebP 像 JPEG 一样对细节丰富的图片信手拈来，像 PNG 一样支持透明，像 GIF 一样可以显示动态图
缺点：WebP 还会增加服务器的负担——和编码 JPG 文件相比，编码同样质量的 WebP 文件会占用更多的计算资源。兼容问题


如何做图片加载异常处理？
逐步加载图像？

## 服务端渲染

优势：首屏优化，seo
缺点:过多占用服务端资源

```
import { renderToString } from 'react-dom/server'
renderToString(<Sth />)
```


## Gzip 压缩

Gzip 的内核就是 Deflate，目前我们压缩文件用得最多的就是 Gzip。
如果项目不是极端迷你的超小型文件，都建议试试Gzip。

- 压缩 Gzip，服务端要花时间；解压 Gzip，浏览器要花时间。中间节省出来的传输时间，真的那么可观吗？

答案是肯定的。如果你手上的项目是 1k、2k 的小文件，那确实不值当。但更多的时候，我们处理的都是具备一定规模的项目文件。实践证明，这种情况下压缩和解压带来的时间开销相对于传输过程中节省下的时间开销来说，可以说是微不足道的。

## 懒加载、预加载
图片：
懒加载，把图片用占位符，把真正的路径存在元素“data-url”属性里。
预加载，提前加载图片，当用户需要查看时可直接从本地缓存中渲染。


## 动画

动画的实现方式
* 可以通过setTimeout和setInterval方法来在脚本中实现动画，但是这样效果可能不够流畅，且会占用额外的资源
* 使用requestAnimationFrame
- 这个方法原理其实也就跟setTimeout/setInterval差不多，通过递归调用同一方法来不断更新画面以达到动起来的效果，
- requestAnimationFrame不需要使用者指定循环间隔时间，浏览器会基于当前页面是否可见、CPU的负荷情况等来自行决定最佳的帧速率，从而更合理地使用CPU。
- 但它优于setTimeout/setInterval的地方在于它是由浏览器专门为动画提供的API，在运行时浏览器会自动优化方法的调用，并且如果页面不是激活状态下的话，动画会自动暂停，有效节省了CPU开销。

```
//用来兼容不同浏览器
window.requestAnimat = (function(){
    return window.requestAnimationFrame ||
    window.webkitRequestAnimationFrame  ||
    window.mozRequestAnimationFrame || function(callback){
        setTimeout(callback, 1000/60);
    }
})();
```

为什么settimeout不够流畅

* 1、即使向其传递毫秒为单位的参数，它们也不能达到ms的准确性。这是因为javascript是单线程的，可能会发生阻塞。
* 2、没有对调用动画的循环机制进行优化。
* 3、没有考虑到绘制动画的最佳时机，只是一味地以某个大致的事件间隔来调用循环。

*** 其实，使用setInterval或setTimeout来实现主循环，根本错误就在于它们抽象等级不符合要求。我们想让浏览器执行的是一套可以控制各种细节的api，实现如“最优帧速率”、“选择绘制下一帧的最佳时机”等功能。但是如果使用它们的话，这些具体的细节就必须由开发者自己来完成。 ***


requestIdleCallback
当关注用户体验，不希望因为一些不重要的任务（如统计上报）导致用户感觉到卡顿的话，就应该考虑使用requestIdleCallback。因为requestIdleCallback回调的执行的前提条件是当前浏览器处于空闲状态。


requestIdleCallback和requestAnimationFrame有什么区别？  
requestAnimationFrame的回调会在每一帧确定执行，属于高优先级任务，而requestIdleCallback的回调则不一定，属于低优先级任务。  
我们所看到的网页，都是浏览器一帧一帧绘制出来的，通常认为FPS为60的时候是比较流畅的，而FPS为个位数的时候就属于用户可以感知到的卡顿了


CSS动画：
animation与transition

区别：
1.动画状态的区别：
animation动画可以通过@keyframes属性对动画进行更为精细的控制，设置多个状态。
但是transition属性则只有两个状态，起始状态与结束状态。
2.子属性的数量不同：
两个属性都是复合属性，包含有若干个子属性，但是数目不相同。
当然子属性数量不同会对效果有影响，很容易区分
3.触发时机不同：
两个属性的触发时机有很大的不同，animation好比是一个自执行函数，只要定义好，立马生效触发动画。
transition则像是一个事件处理函数（事件监听器），只有它监听的属性值发生改变，动画效果才会生效。

*** 我们知道CSS是比js动画要流畅的 *** 

CSS动画流畅的原因:
渲染线程分为main thread(主线程)和compositor thread(合成器线程)。
如果CSS动画只是改变transform和opacity，这时整个CSS动画得以在compositor thread完成（而JS动画则会在main thread执行，然后触发compositor进行下一步操作）
在JS执行一些昂贵的任务时，main thread繁忙，CSS动画由于使用了compositor thread可以保持流畅，


当然，这并非不需要前提（CSS动画比JS流畅的前提）
- JS在执行一些昂贵的任务 同时CSS动画不触发layout或paint
- 在CSS动画或JS动画触发了paint或layout时，需要main thread进行Layer树的重计算，这时CSS动画或JS动画都会阻塞后续操作。
- 只有如下属性的修改才符合“仅触发Composite，不触发layout或paint”：
- backface-visibility、opacity、perspective、perspective-origin、transfrom

所以只有用上了3D加速或修改opacity时，css3动画的优势才会体现出来。（代码相对简单,性能调优方向固定，对于帧速表现不好的低版本浏览器，CSS3可以做到自然降级，而JS则需要撰写额外代码）


## will change
这是一个实验中的功能

CSS 属性 will-change 为web开发者提供了一种告知浏览器该元素会有哪些变化的方法，这样浏览器可以在元素属性真正发生变化之前提前做好对应的优化准备工作。 这种优化可以将一部分复杂的计算工作提前准备好，使页面的反应更为快速灵敏。

```
.sidebar {
  will-change: transform;
}
```
- 不要将 will-change 应用到太多元素上
- 有节制地使用
- 不要过早应用 will-change 优化
- 给它足够的工作时间



## CDN 

CDN其功能是将内容“发布”到离用户最近的服务器上，有效的避免网络拥塞（越远的距离越容易遇到拥塞）。CDN提供就近访问的能力，消除了由于用户离机房的距离不一样带来的体验差异。

我们都知道静态资源要放在CDN上。不仅是加速访问还可以有效的环节业务服务器的压力。并且如上文所说的，如果有很多静态资源的话，每一个请求都要携带cookie，是有很大程度的浪费的。

当然，CDN的使用上也会有一些问题，关于命中率的问题。CDN也有一些常用的优化策略。：静态化缓存优化、动态内容静态边缘化、动态加速优化

## 缓存

服务端缓存：
memcache、redis、数据库缓存
http缓存，如上
客户端缓存：
MemoryCache、localstorage、sessionstorage、cookie、indexdb、websql、service worker

MemoryCache，是指存在内存中的缓存。从优先级上来说，它是浏览器最先尝试去命中的一种缓存。从效率上来说，它是响应速度最快的一种缓存。

localStorage只要在相同的协议、相同的主机名、相同的端口下，就能读取/修改到同一份localStorage数据。
sessionStorage比localStorage更严苛一点，除了协议、主机名、端口外，还要求在同一窗口（也就是浏览器的标签页）下。
sessionStorage当会话结束（当前页面关闭的时候，自动销毁）

cookie 只是我们认为可以作为存储的一种。Cookie 的本职工作并非本地存储，而是“维持状态”。
Cookie 是有体积上限的，它最大只能有 4KB。当 Cookie 超过 4KB 时，它将面临被裁切的命运。这样看来，Cookie 只能用来存取少量的信息。
而且cookie与会自动发送到相同域名下的浏览器，如果cookie 过大，会很大程度上影响性能。所以才有了。我们常说的，静态资源放在CDN上，而且CDN的域名也会有多个。（域名合并是常见的CDN优化手段之一，对于web网页来说，为了提高浏览器的并行下载能力，往往会使用多个域名。）

还有些数据的请求的结果，会放在本地的数据库中。websql、indexdb

## service worker
我们知道service worker 有一个作用是用于离线存储

可以让 Service Worker 成为监听 fetch 事件的中间人,也可以让 Service Worker 保存某些资源在缓存里。当缓存项被请求，Service Worker 无需发出额外的请求就可以返回缓存数据。只要资源被缓存，浏览器无需网络连接就可以展示内容。


```
// 简单实例
// Service Worker监听所有的网络请求，网络请求的产生触发的是fetch事件，
// 可以在其对应的监听函数中实现对请求的拦截，进而判断是否有对应到该请求的缓存，
// 实现从Service Worker中取到缓存的目的
self.addEventListener('fetch', event => {
  event.respondWith(
    // 尝试匹配该请求对应的缓存值
    caches.match(event.request).then(res => {
      // 如果匹配到了，调用Server Worker缓存
      if (res) {
        return res;
      }
      // 如果没匹配到，向服务端发起这个资源请求
      return fetch(event.request).then(response => {
        if (!response || response.status !== 200) {
          return response;
        }
        // 请求成功的话，将请求缓存起来。
        caches.open(cacheName).then(function(cache) {
          console.log('event.request', event.request)
          if (event.request.method !== 'POST' && event.request.url.indexOf('sockjs-node') < 0)  {
            cache.put(event.request, response);
          }
        });
        return response.clone();
      });
    })
  );
});

```

Service Worker 特点: 
- 网站必须使用 HTTPS。除了使用本地开发环境调试时(如域名使用 localhost)
- 运行于浏览器后台，可以控制打开的作用域范围下所有的页面请求
- 单独的作用域范围，单独的运行环境和执行线程
- 不能操作页面 DOM。但可以通过事件机制来处理

## Push Cache

* 1.Service Worker 
* 2.Memory Cache
* 3.Disk Cache


Push Cache（推送缓存）是 HTTP/2 中的内容，当以上三种缓存都没有命中时，它才会被使用。它只在会话（Session）中存在，一旦会话结束就被释放，并且缓存时间也很短暂，在Chrome浏览器中只有5分钟左右，同时它也并非严格执行HTTP头中的缓存指令。

## 工程构建部分

有构建速度、减少包大小、抽离公用模块、上传CDN、开启Gzip等等

一般webpack 优化策略

1、优化Loader，配置include和exclude。同时把Babel编译过的文件缓存起来

```
loader: 'babel-loader?cacheDirectory=ture'
```

2、Happy启用多线程(webpack4 生产模式，默认开启多个子进程（线程）由之前的一个一个压缩，变为并行压缩)
3、DllPlugin将特定的类库提前打包然后引入，极大减少打包类库的构建次数
4、css 抽离mini-css-extract-plugin
5、html-webpack-plugin压缩html，当然html-webpack-plugin不止与于html的压缩
6、合并压缩图片，转换url-loader转换图片
7、Scope Hoisting（尽可能的合并打包出来的模块打一个函数中去）
8、依赖库分离（optimization.splitChunks）
9、按需加载

```
@babel/plugin-syntax-dynamic-import
import (/* webpackChunkName: "authModal" */ 'common/sth/index').then(chunk => {
  let sthModal = chunk.default,
  sthModal();
})
```
10、Tree Shaking（webpack 4 生产环境 默认开启）
11、alias别名的方式来映射一个路径，能让 Webpack 更快找到路径
12、noParse 当确定一个文件下没有其他依赖，就可以使用该属性让 Webpack 不扫描该文件
13、优化模块查找路径
14、preload-webpack-plugin 获取代码拆分的路径
15、webpack.IgnorePlugin(/^\.\/locale$/, /moment$/) 忽略部分内容
- moment这个库中，如果引用了./locale/目录的内容，就忽略掉，不会打包进去
16、ModuleConcatenationPlugin进行scope hoisting（文件体积比之前更小，运行代码时创建的函数作用域也比之前少了，开销也随之变小。）
17、cache-loader来做loader的缓存，加快编译的速度（增量式的）

preload与prefetch 区别： 
- preload 是声明式的 fetch，可以强制浏览器请求资源，同时不阻塞文档 onload 事件。
- Prefetch 提示浏览器这个资源将来可能需要，但是把决定是否和什么时间加载这个资源的决定权交给浏览器。

- preload 提前加载
- preload 顾名思义就是一种预加载的方式，它通过声明向浏览器声明一个需要提交加载的资源，当资源真正被使用的时候立即执行，就无需等待网络的消耗。

- prefetch 预判加载
- prefetch 跟 preload 不同，它的作用是告诉浏览器未来可能会使用到的某个资源，浏览器就会在闲时去加载对应的资源，若能预测到用户的行为，比如懒加载，点击到其它页面等则相当于提前预加载了需要的资源。它的用法跟 preload 是一样的：

*** 什么时候该用 &lt;link rel=”preload”&gt; ？ 什么时候又该用 &lt;link rel=”prefetch”&gt; ? ***

- 对于当前页面很有必要的资源使用 preload，对于可能在将来的页面中使用的资源使用 prefetch。
- preload 是对浏览器指示预先请求当前页需要的资源（关键的脚本，字体，主要图片）。
- prefetch 应用场景稍微又些不同 —— 用户将来可能在其他部分（比如视图或页面）使用到的资源。如果 A 页面发起一个 B 页面的 prefetch 请求，这个资源获取过程和导- 航请求可能是同步进行的，而如果我们用 preload 的话，页面 A 离开时它会立即停止。


## 节流、防抖
* 连续操作：两个操作之间的时间间隔小于设定的阀值，这样子的一连串操作视为连续操作。

throttle函数与debounce函数区别:  
防抖 (debounce): 将多次高频操作优化为只在最后一次执行，通常使用的场景是：用户输入，只需再输入完成后做一次输入校验即可。
节流(throttle): 每隔一段时间后执行一次，也就是降低频率，将高频操作优化成低频操作，通常使用场景: 滚动条事件 或者 resize 事件，通常每隔 100~500 ms执行一次即可。

debounce（防抖）：一个连续操作中的处理，只触发一次，从而实现防抖动。
throttle：一个连续操作中的处理，按照阀值时间间隔进行触发，从而实现节流。（throttle 可以限制函数调⽤用的频率,常⽤用来防⽌止按钮被重复点击。）

- “节流”与“防抖”的本质:这两个东西都以闭包的形式存在。它们通过对事件对应的回调函数进行包裹、以自由变量的形式缓存时间信息，最后用 setTimeout 来控制事件的触发频率。
- throttle 的中心思想在于：在某段时间内，不管你触发了多少次回调，我都只认第一次，并在计时结束时给予响应。
- 防抖(debounce)的中心思想在于：我会等你到底。在某段时间内，不管你触发了多少次回调，我都只认最后一次。

throttle函数与debounce函数的区别就是：throttle函数在触发后会马上执行，而debounce函数会在一定延迟后才执行。从触发开始到延迟结束，只执行函数一次

### debounce 的问题
debounce 的问题在于它“太有耐心了”。如果用户的操作十分频繁——他每次都不等 debounce 设置的 delay 时间结束就进行下一次操作，于是每次 debounce 都为该用户重新生成定时器，回调函数被延迟了不计其数次。频繁的延迟会导致用户迟迟得不到响应，用户同样会产生“这个页面卡死了”的观感。
- 用 Throttle 来优化 Debounce

```
// fn是我们需要包装的事件回调, delay是时间间隔的阈值
function throttle(fn, delay) {
  // last为上一次触发回调的时间, timer是定时器
  let last = 0, timer = null
  // 将throttle处理结果当作函数返回
  
  return function () { 
    // 保留调用时的this上下文
    let context = this
    // 保留调用时传入的参数
    let args = arguments
    // 记录本次触发回调的时间
    let now = +new Date()
    
    // 判断上次触发的时间和本次触发的时间差是否小于时间间隔的阈值
    if (now - last < delay) {
    // 如果时间间隔小于我们设定的时间间隔阈值，则为本次触发操作设立一个新的定时器
       clearTimeout(timer)
       timer = setTimeout(function () {
          last = now
          fn.apply(context, args)
        }, delay)
    } else {
        // 如果时间间隔超出了我们设定的时间间隔阈值，那就不等了，无论如何要反馈给用户一次响应
        last = now
        fn.apply(context, args)
    }
  }
}

// 用新的throttle包装scroll的回调
const better_scroll = throttle(() => console.log('触发了滚动事件'), 1000)

document.addEventListener('scroll', better_scroll)

```


## 性能检测与分析

YSlow、PageSpeed、lightHouse（可以通过npm安装、安装chrome插件，chrome的Audits）、performance

performance
```
if (window.performance && typeof window.performance.getEntriesByType === 'function') {
  this.resources = window.performance.getEntriesByType('resource');
  this.marks = window.performance.getEntriesByType('mark');
  this.measures = window.performance.getEntriesByType('measure');
  this.timing = window.performance.getEntriesByType('navigation')[0];
  this.paint = window.performance.getEntriesByType('paint');
} else if (window.performance && typeof window.performance.webkitGetEntriesByType === 'function') {
  this.resources = window.performance.webkitGetEntriesByType('resource');
  this.marks = window.performance.webkitGetEntriesByType('mark');
  this.measures = window.performance.webkitGetEntriesByType('measure');
  this.timing = window.performance.webkitGetEntriesByType('navigation')[0];
  this.paint = window.performance.webkitGetEntriesByType('paint');
}


this.timing = this.timing || (window.performance && window.performance.timing);

let rst = {
  // 关键性能指标
  fb: this.timing.responseStart - this.timing.domainLookupStart, // first byte
  fpt: this.timing.responseEnd - this.timing.fetchStart,         // first paint time 白屏
  tti: this.timing.domInteractive - this.timing.fetchStart,      // 首次可交互
  ready: this.timing.domContentLoadedEventEnd - this.timing.fetchStart,
  load: this.timing.loadEventStart - this.timing.fetchStart,
};

// 传输资源大小，用于判断文件是大小是否合适、是否开启了压缩(如 gzip)
if (this.timing.transferSize !== undefined) {
  rst.transferSize = this.timing.transferSize;       // 文档 + 头部信息大小
  rst.encodedBodySize = this.timing.encodedBodySize; // 压缩文档大小
  rst.decodedBodySize = this.timing.decodedBodySize; // 解压文档大小
}
const [firstPaint, firstContentfulPaint] = this.paint;
if (firstPaint) {
  rst.fp = firstPaint.startTime;            // 准确的白屏时间
  rst.fcp = firstContentfulPaint.startTime; // 准确的灰屏时间
}

console.log(rst)
```


TODO性能监控体系搭建

关键指标
* 客观度量指标
  - 文档加载（Time to fistbyte、DomContentLoaded、Load）
  - 内容呈现（Fist paint、Fist Contentful Paint、Fist Meaningful paint、Largest Contentful Paint、Speed Index、First Screen Paint）
  - 交互响应（First Cpu idle、Time to Interactive、First Input delay、Frames per Second）
* 用户体验核心指标
  - 白屏时间
  - 首屏时间
  - 可交互时间
  - 可流畅交互时间



***运行时性能瓶颈分析***


## 雅虎军规35条

### 内容部分 
1.尽量减少HTTP请求数
2.减少DNS查找
3.避免重定向
4.让Ajax可缓存
5.延迟加载组件
6.预加载组件
7.减少DOM元素的数量
8.跨域分离组件
9.尽量少用iframe
10.杜绝404

### css部分 
11.避免使用CSS表达式 
12.选择舍弃@import 
13.避免使用滤镜 
14.把样式表放在顶部 

### js部分 
15.去除重复脚本 
16.尽量减少DOM访问 
17.用智能的事件处理器 
18.把脚本放在底部 

javascript, css 
19.把JavaScript和CSS放到外面 
20.压缩JavaScript和CSS 

### 图片 
21.优化图片 
22.优化CSS Sprite 
23.不要用HTML缩放图片 
24.用小的可缓存的favicon.ico（P.S. 收藏夹图标） 

### cookie 
25.给Cookie减肥 

### 服务器 
34.使用CDN（内容分发网络） 
35.添上Expires或者Cache-Control HTTP头 

## 高性能网站建设指南 

《高性能网站建设指南》 总结了12条基本规则
* 尽量减少http请求
* 使用CDN
* 静态资源使用cahce
* 启用Gzip压缩
* JavaScript脚本尽量放在页面底部
* CSS 表达式放在顶部
* 避免CSS表达式
* 减少内联Javascript和css 的使用，尽可能使用外部的js和css文件
* 减少DNS查询
* 精简js
* 避免重定向
* 删除重复的脚本