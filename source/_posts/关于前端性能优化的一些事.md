---
title: 关于前端性能优化的一些事
date: 2019-12-10 20:25:37
tags: 技术
---

- 前端性能优化零碎知识点的一些东西，可能相对比较不太成”体统“简单理下，零碎的但必要的知识点。
从“输入 URL 到页面加载完成，发生了什么”的角度简单梳理一遍

- DNS 解析
- TCP 连接
- HTTP 请求发送
- 服务端处理请求，响应返回
- 浏览器拿到响应数据，解析响应内容，把解析的结果展示给用户

稍微详细点儿：

- 回车url到cpu中断，响应键盘操作
- 浏览器解析url到开启网络请求线程
- DNS解析域名映射对应的ip地址， arp地址解析，实现IP地址到MAC地址的转换。 
- 开启网络线程到发出一个完整的http请求
- 从服务器接收到请求到对应后台接收到请求
- 后台和前台的http交互
- 浏览器接收到http数据包后的解析流程（解析html-词法分析然后解析成dom树、解析css生成css规则树、合并成render树，然后layout、painting渲染、复合图层的合成、GPU绘制、外链资源的处理、loaded和domcontentloaded等）
- JS引擎解析过程（JS的解释阶段，预处理阶段，执行阶段生成执行上下文，VO，作用域链、回收机制等等）

## DNS查询 
我们知道dns解析是耗时的。

对于页面请求域名，如果DNS Lookup 时间过长会引起白屏的时间过长
对于图片对应的域名，如果DNS Lookup 时间过长，白图的时间也会过长

如果解析域名过多，会让首屏加载变得过慢。

dns解析成IP，大致流程：

如果浏览器有缓存，直接使用浏览器缓存，否则使用本机缓存，再没有的话就是用host
如果本地没有，就向dns域名服务器查询（中间可能还会经过路由器、ISP 的缓存），查询到对应的IP

- 域名查询时有可能是经过了CDN调度器的（如果有cdn存储功能的话）

## DNS优化

DNS Prefetch，即DNS预解析就是根据浏览器定义的规则，提前解析之后可能会用到的域名，使解析结果缓存到系统缓存中，缩短DNS解析时间，来提高网站的访问速度。

>当然还有设置合理的TTL时间、DNS多点就近部署架构升级、基于Anycast的DNS解析架构（未来DNS的优化方向）

*** 打开和关闭DNS预读取  *** 

可以通过在服务器端发送 X-DNS-Prefetch-Control 报头，或是在文档中使用值为 http-equiv 的标签：
&lt;meta http-equiv="x-dns-prefetch-control" content="off"&gt;

强制查询特定主机名 
你可以通过使用 rel 属性值为 link type 中的 dns-prefetch 的 标签来对特定域名进行预读取：
&lt;link rel="dns-prefetch" href="http://www.xxx.com/"&gt;


## HttpDNS

我们知道，DNS一定会存在的问题就是：域名更新问题、解析延迟。那HTTPDns就登场了

- 定义：不走传统的DNS解析，而是自己搭建基于HTTP协议的DNS服务器集群，分布在多个地点和多个运营商，当客户端需要DNS解析的时候，直接通过HTTP协议进行请求这个服务器集群，获得就近的地址。

HttpDNS是通过ip直接请求http获取服务器A记录地址，不存在向本地运营商询问domain解析过程，所以从根本避免了劫持问题。同时由于是ip直接访问省掉了一次domain解析过程，可以在一定程度上降低平均访问延迟。

## http

http耗时 = TCP握手 通过三次握手建立连接（四次挥手）
https耗时 = TCP握手 + SSL握手


http请求过程（请求应答模式）：
第一次: CLIENT----syn----->SERVER
第二次: SERVER----ack,syn---->CLIENT
第三次: CLIENT----ack----->SERVER
这样，从client---->server, server---->client各自通过一次syn,ack形成闭环，理论上形成了一个近似可靠的通信。

类似于TCP的三次握手，四次挥手的四步：
Client---fin,ack--->Server
Server---ack---->Clinet
Server---fin,ack--->Client
Client----ack----->Server

- SYN：同步序列编号（Synchronize Sequence Numbers）。是TCP/IP建立连接时使用的握手信号。在客户机和服务器之间建立正常的TCP网络连接时，客户机首先发出一个SYN消息，服务器使用SYN+ACK应答表示接收到了这个消息，最后客户机再以ACK消息响应。这样在客户机和服务器之间才能建立起可靠的TCP连接，数据才可以在客户机和服务器之间传递。
- ACK (Acknowledgement）即是确认字符，在数据通信中，接收站发给发送站的一种传输类控制字符。表示发来的数据已确认接收无误。
在TCP/IP协议中，如果接收方成功的接收到数据，那么会回复一个ACK数据。通常ACK信号有自己固定的格式,长度大小,由接收方回复给发送方。

## http1.0、1.1、2.0区别与联系

http1.1与http1.0 的最大区别就是：长链接、节约带宽、HOST域
与性能相关的是：长链接。HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。
节约带宽：HTTP 1.1支持只发送header信息(不带任何body信息)，如果服务器认为客户端有权限请求服务器，则返回100，否则返回401。客户端如果接受到100，才开始把请求body发送到服务器。这样当服务器返回401的时候，客户端就可以不用发送请求body了，节约了带宽。另外HTTP还支持传送内容的一部分。这样当客户端已经有一部分的资源后，只需要跟服务器请求另外的部分资源即可。这是支持文件断点续传的基础。

哪怕如此，HTTP1.1还是存在效率问题。单个 TCP 连接在同一时刻只能处理一个请求，是说：两个请求的生命周期不能重叠，任意两个 HTTP 请求从开始到结束的时间在同一个 TCP 连接里不能重叠。（虽然有了管道机制pipelining，在同一个TCP链接里，客户端可以发送多个请求，但是服务器还是按照顺序，先回应前面的，完成后，在回应后面的）

问题一：串行的文件传输。当请求a文件时，b文件只能等待，等待a连接到服务器、服务器处理文件、服务器返回文件，这三个步骤。我们假设这三步用时都是1秒，那么a文件用时为3秒，b文件传输完成用时为6秒，依此类推。（注：此项计算有一个前提条件，就是浏览器和服务器是单通道传输）
问题二：连接数过多。我们假设Apache设置了最大并发数为300，因为浏览器限制，浏览器发起的最大请求数为6，也就是服务器能承载的最高并发为50，当第51个人访问时，就需要等待前面某个请求处理完成。

然后http2.0 来了 解决这些问题

解决第一个：在HTTP1.1的协议中，我们传输的request和response都是基本于文本的，这样就会引发一个问题：所有的数据必须按顺序传输，比如需要传输：hello world，只能从h到d一个一个的传输，不能并行传输，因为接收端并不知道这些字符的顺序，所以并行传输在HTTP1.1是不能实现的。

- HTTP/2引入二进制数据帧和流的概念，其中帧对数据进行顺序标识，这样浏览器收到数据之后，就可以按照序列对数据进行合并，而不会出现合并后数据错乱的情况。同样是因为有了序列，服务器就可以并行的传输数据，这就是流所做的事情。

解决第二个问题：HTTP/2对同一域名下所有请求都是基于流，也就是说同一域名不管访问多少文件，也只建立一路连接。同样Apache的最大连接数为300，因为有了这个新特性，最大的并发就可以提升到300，比原来提升了6倍！

综上HTTP1.1与HTTP 2.0的主要区别
- 多路复用
- 二进制分帧
- 首部压缩
- 服务器推送

HTTP 2.0 采用 HTTPS ，HTTPS 基于 SSL/TLS。现在绝大部分的站点都会采用https，也就会引入hsts。

HSTS的作用是强制客户端（如浏览器）使用HTTPS与服务器创建连接。HSTS 的作用是为了在用户通过 HTTP 访问网站时不需要服务器做 301/302 跳转，直接一个 307 本地强制使用 HTTPS 访问网站，这可以防止用户在第一次发出请求时被劫持，也减少了一次请求。

## https过程
如何如何加密、解密。为什么要对称和非对称

## 负载均衡

nginx实现负载均衡的几种方式

## 响应

### http 缓存

服务端返回结果，缓存

返回结果，给到客户端

强缓存
协商缓存

### 页面解析

浏览器内核拿到内容后，渲染步骤大致可以分为以下几步：
1. 解析HTML，构建DOM树
2. 解析CSS，生成CSS规则树
3. 合并DOM树和CSS规则，生成render树
4. 布局render树（Layout/reflow），负责各元素尺寸、位置的计算（从根节点递归调用，计算每一个元素的大小、位置等）
5. 绘制render树（paint），绘制页面像素信息。（在这一步中浏览器会根据我们的 DOM 代码结果，把每一个页面图层转换为像素，并对所有的媒体文件进行解码。）
6. 浏览器会将各层的信息发送给GPU，GPU会将各层合成（composite），显示在屏幕上

### HTML解析，构建DOM

渲染树（Render-Tree）的关键渲染路径中，要求同时具有 DOM 和 CSSOM，之后才会构建渲染树。即，HTML 和 CSS 都是阻塞渲染的资源。

减少DOM元素的数量、而且尽量少用iframe更要杜绝404


### 解析CSS
CSS下载时异步，不会阻塞浏览器构建DOM树.但是会阻塞渲染，也就是在构建render时，会等到css下载解析完毕后才进行（这点与浏览器优化有关，防止css规则不断改变，避免了重复的构建）
CSS 是阻塞渲染的资源。需要将它尽早、尽快地下载到客户端，以便缩短首次渲染的时间。

- media query声明的CSS是不会阻塞渲染的
精简 CSS 并尽快提供它.除此之外，还可以用媒体类型（media type）和媒体查询（media query）来解除对渲染的阻塞。
<link href="index.css" rel="stylesheet">
<link href="print.css" rel="stylesheet" media="print">
<link href="other.css" rel="stylesheet" media="(min-width: 30em) and (orientation: landscape)">


1、为什么一再强调css放在头部 ？
其实现代浏览器为了更好的用户体验,渲染引擎将尝试尽快在屏幕上显示的内容。它不会等到所有HTML解析之前开始构建和布局渲染树。部分的内容将被解析并显示。也就是说浏览器能够渲染不完整的dom树和cssom，尽快的减少白屏的时间。假如我们将js放在header，js将阻塞解析dom，dom的内容会影响到First Paint，导致First Paint延后。所以说我们会将js放在后面，以减少First Paint的时间，但是不会减少DOMContentLoaded被触发的时间。

2、css 逆向匹配为什么会提高匹配效率？
HTML 结构变复杂，CSS 规则表变庞大，那么，逆向匹配的优势就远大于正向匹配了，因为匹配的情况远远低于不匹配的情况。另外，如果在选择器结尾加上通配符「*」，那么「逆向匹配」的优势就大打折扣了，这也就是很多优化原则提到的「尽量避免在选择器末尾添加通配符」的原因。


### js 引擎的解析流程
JS脚本资源的处理有几个特点：
- 阻塞浏览器的解析，也就是说发现一个外链脚本时，需等待脚本下载完成并执行后才会继续解析HTML
- 浏览器的优化，一般现代浏览器有优化，在脚本阻塞时，也会继续下载其它资源（当然有并发上限），但是虽然脚本可以并行下载，解析过程仍然是阻塞的，也就是说必须这个脚本执行完毕后才会接下来的解析，并行下载只是一种优化而已

前面有提到遇到JS脚本时，会等到它的执行，实际上是需要引擎解析的

减少闭包、tree shaking减少多余的代码
js脚本也会阻塞渲染。所以，不管外链还是内部脚本，都应当尽量放在页面底部。

但是可以加上defer或async属性，这样脚本就变成异步的了，可以等到解析完毕后再执行

- defer与async的区别是：defer要等到整个页面在内存中正常渲染结束（DOM 结构完全生成，以及其他脚本执行完成），才会执行；async一旦下载完，渲染引擎就会中断渲染，执行这个脚本以后，再继续渲染。
- 即：defer是“渲染完再执行”，async是“下载完就执行”。
- 另外，如果有多个defer脚本，会按照它们在页面出现的顺序加载，而多个async脚本是不能保证加载顺序的。
- 注意 async 与 defer 属性对于 inline-script 都是无效的。

#### JS的解释阶段

JS是解释型语音，所以它无需提前编译，而是由解释器实时运行

JIT编译器将源码编译成机器码运行

#### JS的解释阶段

JS是解释型语言，所以它无需提前编译，而是由解释器实时运行
为了提高运行速度，现代浏览器一般采用即时编译（JIT-Just In Time compiler）

即字节码只在运行时编译，用到哪一行就编译哪一行，并且把编译结果缓存（inline cache）
这样整个程序的运行速度能得到显著提升。
而且，不同浏览器策略可能还不同，有的浏览器就省略了字节码的翻译步骤，直接转为机器码（如chrome的v8）
总结起来可以认为是： 核心的JIT编译器将源码编译成机器码运行

#### 预处理阶段
1、分号补全
2、变量提升
3、...

### JS的执行阶段
求值策略：
"传值调用"（call by value）
"传名调用"（call by name）


#### 回收机制
降低内存泄露的风险
设置定时器的回收
dom元素的回收
事件的回收
卸载组件之后对应内存的释放
通过WeakMap解决内存泄漏问题


## 闭包
闭包是指有权访问另外一个函数作用域中的变量的函数.可以理解为(能够读取其他函数内部变量的函数)
闭包的作用: 正常函数执行完毕后,里面声明的变量被垃圾回收处理掉,但是闭包可以让作用域里的变量,在函数执行完之后依旧保持没有被垃圾回收处理掉。
应用闭包的主要场合是：设计私有的方法和变量。

闭包的缺陷：闭包的缺点就是常驻内存会增大内存使用量，并且使用不当很容易造成内存泄露。如果不是因为某些特殊任务而需要闭包，在没有必要的情况下，在其它函数中创建函数是不明智的，因为闭包对脚本性能具有负面影响，包括处理速度和内存消耗。

适当减少闭包的使用。

## event loop
微任务，宏任务

理解事件循环机制，巧用宏任务与微任务。

## Flush 队列：浏览器并没有那么简单

## 简单层与复合层

## 图片

遇到图片等资源时，直接就是异步下载，不会阻塞解析，下载完毕后直接用图片替换原有src的地方


图片格式、大小、策略、
图片加载异常处理


## 服务端渲染

优势
场景
缺点


## Gzip 压缩

Gzip 的内核就是 Deflate，目前我们压缩文件用得最多的就是 Gzip。
如果项目不是极端迷你的超小型文件，都建议试试Gzip。

- 压缩 Gzip，服务端要花时间；解压 Gzip，浏览器要花时间。中间节省出来的传输时间，真的那么可观吗？

答案是肯定的。如果你手上的项目是 1k、2k 的小文件，那确实不值当。但更多的时候，我们处理的都是具备一定规模的项目文件。实践证明，这种情况下压缩和解压带来的时间开销相对于传输过程中节省下的时间开销来说，可以说是微不足道的。

## 懒加载、预加载
图片：
懒加载，把图片用占位符，把真正的路径存在元素“data-url”属性里。
预加载，提前加载图片，当用户需要查看时可直接从本地缓存中渲染。


## 动画

动画的实现方式
通过js
可以通过setTimeout和setInterval方法来在脚本中实现动画，但是这样效果可能不够流畅，且会占用额外的资源

也可以使用requestAnimationFrame
也可这个方法原理其实也就跟setTimeout/setInterval差不多，通过递归调用同一方法来不断更新画面以达到动起来的效果，但它优于setTimeout/setInterval的地方在于它是由浏览器专门为动画提供的API，在运行时浏览器会自动优化方法的调用，并且如果页面不是激活状态下的话，动画会自动暂停，有效节省了CPU开销。

requestAnimationFrame与setTimeout的区别

通过CSS




CSS动画流畅的原因:
渲染线程分为main thread(主线程)和compositor thread(合成器线程)。
如果CSS动画只是改变transform和opacity，这时整个CSS动画得以在compositor thread完成（而JS动画则会在main thread执行，然后触发compositor进行下一步操作）
在JS执行一些昂贵的任务时，main thread繁忙，CSS动画由于使用了compositor thread可以保持流畅，


CSS动画比JS流畅的前提：
- JS在执行一些昂贵的任务 同时CSS动画不触发layout或paint
- 在CSS动画或JS动画触发了paint或layout时，需要main thread进行Layer树的重计算，这时CSS动画或JS动画都会阻塞后续操作。
- 只有如下属性的修改才符合“仅触发Composite，不触发layout或paint”：
- backface-visibility
- opacity
- perspective
- perspective-origin
- transfrom

所以只有用上了3D加速或修改opacity时，css3动画的优势才会体现出来。
(2)代码相对简单,性能调优方向固定
(3)对于帧速表现不好的低版本浏览器，CSS3可以做到自然降级，而JS则需要撰写额外代码


requestIdleCallback和requestAnimationFrame有什么区别？
requestAnimationFrame的回调会在每一帧确定执行，属于高优先级任务，而requestIdleCallback的回调则不一定，属于低优先级任务。
我们所看到的网页，都是浏览器一帧一帧绘制出来的，通常认为FPS为60的时候是比较流畅的，而FPS为个位数的时候就属于用户可以感知到的卡顿了，




## will change
这是一个实验中的功能

CSS 属性 will-change 为web开发者提供了一种告知浏览器该元素会有哪些变化的方法，这样浏览器可以在元素属性真正发生变化之前提前做好对应的优化准备工作。 这种优化可以将一部分复杂的计算工作提前准备好，使页面的反应更为快速灵敏。

- 不要将 will-change 应用到太多元素上
- 有节制地使用
- 不要过早应用 will-change 优化
- 给它足够的工作时间

## CDN 

CDN其功能是将内容“发布”到离用户最近的服务器上，有效的避免网络拥塞（越远的距离越容易遇到拥塞）。CDN提供就近访问的能力，消除了由于用户离机房的距离不一样带来的体验差异。

我们都知道静态资源要放在CDN上。不仅是加速访问还可以有效的环节业务服务器的压力。并且如上文所说的，如果有很多静态资源的话，每一个请求都要携带cookie，是有很大程度的浪费的。

当然，CDN的使用上也会有一些问题，关于命中率的问题。CDN也有一些常用的优化策略。：静态化缓存优化、动态内容静态边缘化、动态加速优化

## 缓存

服务端缓存：
memcache、redis、数据库缓存
http缓存，如上
客户端缓存：
MemoryCache、localstorage、sessionstorage、cookie、indexdb、websql、service worker（见下）

MemoryCache，是指存在内存中的缓存。从优先级上来说，它是浏览器最先尝试去命中的一种缓存。从效率上来说，它是响应速度最快的一种缓存。

localStorage只要在相同的协议、相同的主机名、相同的端口下，就能读取/修改到同一份localStorage数据。
sessionStorage比localStorage更严苛一点，除了协议、主机名、端口外，还要求在同一窗口（也就是浏览器的标签页）下。
sessionStorage当会话结束（当前页面关闭的时候，自动销毁）

cookie 只是我们认为可以作为存储的一种。Cookie 的本职工作并非本地存储，而是“维持状态”。
Cookie 是有体积上限的，它最大只能有 4KB。当 Cookie 超过 4KB 时，它将面临被裁切的命运。这样看来，Cookie 只能用来存取少量的信息。
而且cookie与会自动发送到相同域名下的浏览器，如果cookie 过大，会很大程度上影响性能。所以才有了。我们常说的，静态资源放在CDN上，而且CDN的域名也会有多个。（域名合并是常见的CDN优化手段之一，对于web网页来说，为了提高浏览器的并行下载能力，往往会使用多个域名。）

还有些数据的请求的结果，会放在本地的数据库中。websql、indexdb

## service worker
service worker 我们都知道有一个作用是用于离线存储
你可以让 Service Worker 成为监听 fetch 事件的中间人。你也可以让 Service Worker 保存某些资源在缓存里。当缓存项被请求，Service Worker 无需发出额外的请求就可以返回缓存数据。只要资源被缓存，浏览器无需网络连接就可以展示内容。


```
// 简单实例
// Service Worker监听所有的网络请求，网络请求的产生触发的是fetch事件，
// 可以在其对应的监听函数中实现对请求的拦截，进而判断是否有对应到该请求的缓存，
// 实现从Service Worker中取到缓存的目的
self.addEventListener('fetch', event => {
  event.respondWith(
    // 尝试匹配该请求对应的缓存值
    caches.match(event.request).then(res => {
      // 如果匹配到了，调用Server Worker缓存
      if (res) {
        return res;
      }
      // 如果没匹配到，向服务端发起这个资源请求
      return fetch(event.request).then(response => {
        if (!response || response.status !== 200) {
          return response;
        }
        // 请求成功的话，将请求缓存起来。
        caches.open(cacheName).then(function(cache) {
          console.log('event.request', event.request)
          if (event.request.method !== 'POST' && event.request.url.indexOf('sockjs-node') < 0)  {
            cache.put(event.request, response);
          }
        });
        return response.clone();
      });
    })
  );
});

```

## Push Cache

1.Service Worker
2.Memory Cache
3.Disk Cache


Push Cache（推送缓存）是 HTTP/2 中的内容，当以上三种缓存都没有命中时，它才会被使用。它只在会话（Session）中存在，一旦会话结束就被释放，并且缓存时间也很短暂，在Chrome浏览器中只有5分钟左右，同时它也并非严格执行HTTP头中的缓存指令。

https://www.jianshu.com/p/54cc04190252


## 工程构建部分
构建速度、包大小、抽离公用部分、CDN

webpack 构建优化、react框架本身的优化visial dom。异步的setState、fiber架构

webpack 优化策略。
1、优化Loader，配置include和exclude。同时把Babel编译过的文件缓存起来

```
loader: 'babel-loader?cacheDirectory=ture'
```

2、Happy启用多线程
3、DllPlugin将特定的类库提前打包然后引入，极大减少打包类库的构建次数
4、css 抽离mini-css-extract-plugin
5、html-webpack-plugin压缩html，当然html-webpack-plugin不止与html的压缩
6、合并压缩图片
7、base64 转换
8、依赖库分离（optimization.splitChunks）
9、按需加载
```
@babel/plugin-syntax-dynamic-import

import (/* webpackChunkName: "authModal" */ 'common/authModal/index').then(chunk => {
    let initAuthModal = chunk.default,
        nick = rcl.get('seller_nick', 'session');
    let isSubNick = nick.includes(':');
    initAuthModal(isSubNick);
})
```
10、删除冗余代码 ，针对于支持es6模块化的自动开启tree shaking
11、alias
12、noParse
13、优化模块查找路径
14、preload-webpack-plugin 获取代码拆分的路径


preload与prefetch 区别：
preload 是声明式的 fetch，可以强制浏览器请求资源，同时不阻塞文档 onload 事件。
Prefetch 提示浏览器这个资源将来可能需要，但是把决定是否和什么时间加载这个资源的决定权交给浏览器。

preload 提前加载
preload 顾名思义就是一种预加载的方式，它通过声明向浏览器声明一个需要提交加载的资源，当资源真正被使用的时候立即执行，就无需等待网络的消耗。

prefetch 预判加载
prefetch 跟 preload 不同，它的作用是告诉浏览器未来可能会使用到的某个资源，浏览器就会在闲时去加载对应的资源，若能预测到用户的行为，比如懒加载，点击到其它页面等则相当于提前预加载了需要的资源。它的用法跟 preload 是一样的：

什么时候该用 <link rel=”preload”> ？ 什么时候又该用 <link rel=”prefetch”> ?
对于当前页面很有必要的资源使用 preload，对于可能在将来的页面中使用的资源使用 prefetch。
preload 是对浏览器指示预先请求当前页需要的资源（关键的脚本，字体，主要图片）。
prefetch 应用场景稍微又些不同 —— 用户将来可能在其他部分（比如视图或页面）使用到的资源。如果 A 页面发起一个 B 页面的 prefetch 请求，这个资源获取过程和导航请求可能是同步进行的，而如果我们用 preload 的话，页面 A 离开时它会立即停止。
使用 preload和 prefetch，我们有了对当前页面和将来页面加载关键资源的解决办法。



## 节流、防抖

throttle函数与debounce函数区别:
防抖 (debounce): 将多次高频操作优化为只在最后一次执行，通常使用的场景是：用户输入，只需再输入完成后做一次输入校验即可。
节流(throttle): 每隔一段时间后执行一次，也就是降低频率，将高频操作优化成低频操作，通常使用场景: 滚动条事件 或者 resize 事件，通常每隔 100~500 ms执行一次即可。

连续操作：两个操作之间的时间间隔小于设定的阀值，这样子的一连串操作视为连续操作。
debounce（防抖）：一个连续操作中的处理，只触发一次，从而实现防抖动。
throttle：一个连续操作中的处理，按照阀值时间间隔进行触发，从而实现节流。（throttle 可以限制函数调⽤用的频率,常⽤用来防⽌止按钮被重复点击。）

- “节流”与“防抖”的本质:这两个东西都以闭包的形式存在。它们通过对事件对应的回调函数进行包裹、以自由变量的形式缓存时间信息，最后用 setTimeout 来控制事件的触发频率。
- throttle 的中心思想在于：在某段时间内，不管你触发了多少次回调，我都只认第一次，并在计时结束时给予响应。
- 防抖(debounce)的中心思想在于：我会等你到底。在某段时间内，不管你触发了多少次回调，我都只认最后一次。

throttle函数与debounce函数的区别就是：throttle函数在触发后会马上执行，而debounce函数会在一定延迟后才执行。从触发开始到延迟结束，只执行函数一次

### debounce 的问题
debounce 的问题在于它“太有耐心了”。如果用户的操作十分频繁——他每次都不等 debounce 设置的 delay 时间结束就进行下一次操作，于是每次 debounce 都为该用户重新生成定时器，回调函数被延迟了不计其数次。频繁的延迟会导致用户迟迟得不到响应，用户同样会产生“这个页面卡死了”的观感。
- 用 Throttle 来优化 Debounce

```
// fn是我们需要包装的事件回调, delay是时间间隔的阈值
function throttle(fn, delay) {
  // last为上一次触发回调的时间, timer是定时器
  let last = 0, timer = null
  // 将throttle处理结果当作函数返回
  
  return function () { 
    // 保留调用时的this上下文
    let context = this
    // 保留调用时传入的参数
    let args = arguments
    // 记录本次触发回调的时间
    let now = +new Date()
    
    // 判断上次触发的时间和本次触发的时间差是否小于时间间隔的阈值
    if (now - last < delay) {
    // 如果时间间隔小于我们设定的时间间隔阈值，则为本次触发操作设立一个新的定时器
       clearTimeout(timer)
       timer = setTimeout(function () {
          last = now
          fn.apply(context, args)
        }, delay)
    } else {
        // 如果时间间隔超出了我们设定的时间间隔阈值，那就不等了，无论如何要反馈给用户一次响应
        last = now
        fn.apply(context, args)
    }
  }
}

// 用新的throttle包装scroll的回调
const better_scroll = throttle(() => console.log('触发了滚动事件'), 1000)

document.addEventListener('scroll', better_scroll)

```


## 性能检测与分析

YSlow、PageSpeed、lightHouse（可以通过npm安装、安装chrome插件，chrome的Audits）、performance

***运行时性能瓶颈分析***


## 雅虎军规35条

### 内容部分 
1.尽量减少HTTP请求数
2.减少DNS查找
3.避免重定向
4.让Ajax可缓存
5.延迟加载组件
6.预加载组件
7.减少DOM元素的数量
8.跨域分离组件
9.尽量少用iframe
10.杜绝404

### css部分 
11.避免使用CSS表达式 
12.选择舍弃@import 
13.避免使用滤镜 
14.把样式表放在顶部 

### js部分 
15.去除重复脚本 
16.尽量减少DOM访问 
17.用智能的事件处理器 
18.把脚本放在底部 

javascript, css 
19.把JavaScript和CSS放到外面 
20.压缩JavaScript和CSS 

### 图片 
21.优化图片 
22.优化CSS Sprite 
23.不要用HTML缩放图片 
24.用小的可缓存的favicon.ico（P.S. 收藏夹图标） 

### cookie 
25.给Cookie减肥 

### 服务器 
34.使用CDN（内容分发网络） 
35.添上Expires或者Cache-Control HTTP头 

## 高性能网站建设指南 

《高性能网站建设指南》 总结了12条基本规则
* 尽量减少http请求
* 使用CDN
* 静态资源使用cahce
* 启用Gzip压缩
* JavaScript脚本尽量放在页面底部
* CSS 表达式放在顶部
* 避免CSS表达式
* 减少内联Javascript和css 的使用，尽可能使用外部的js和css文件
* 减少DNS查询
* 精简js
* 避免重定向
* 删除重复的脚本
s